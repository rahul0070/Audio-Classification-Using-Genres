{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN on spectrogram images of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io.wavfile import read, write\n",
    "import playsound\n",
    "import os \n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from os import path\n",
    "\n",
    "#from PIL import Image\n",
    "import pathlib\n",
    "import csv \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import warnings\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files: 0 files [00:00, ? files/s]\u001b[A\n",
      "Copying files: 63 files [00:00, 624.59 files/s]\u001b[A\n",
      "Copying files: 133 files [00:00, 643.54 files/s]\u001b[A\n",
      "Copying files: 196 files [00:00, 638.62 files/s]\u001b[A\n",
      "Copying files: 256 files [00:00, 624.94 files/s]\u001b[A\n",
      "Copying files: 311 files [00:00, 598.45 files/s]\u001b[A\n",
      "Copying files: 361 files [00:00, 556.17 files/s]\u001b[A\n",
      "Copying files: 411 files [00:00, 486.74 files/s]\u001b[A\n",
      "Copying files: 457 files [00:00, 477.31 files/s]\u001b[A\n",
      "Copying files: 503 files [00:00, 467.99 files/s]\u001b[A\n",
      "Copying files: 549 files [00:01, 439.31 files/s]\u001b[A\n",
      "Copying files: 593 files [00:01, 429.59 files/s]\u001b[A\n",
      "Copying files: 636 files [00:01, 412.55 files/s]\u001b[A\n",
      "Copying files: 678 files [00:01, 410.63 files/s]\u001b[A\n",
      "Copying files: 719 files [00:01, 404.71 files/s]\u001b[A\n",
      "Copying files: 760 files [00:01, 392.62 files/s]\u001b[A\n",
      "Copying files: 800 files [00:01, 390.50 files/s]\u001b[A\n",
      "Copying files: 840 files [00:01, 351.22 files/s]\u001b[A\n",
      "Copying files: 880 files [00:01, 361.86 files/s]\u001b[A\n",
      "Copying files: 917 files [00:02, 360.29 files/s]\u001b[A\n",
      "Copying files: 954 files [00:02, 358.17 files/s]\u001b[A\n",
      "Copying files: 991 files [00:02, 357.04 files/s]\u001b[A\n",
      "Copying files: 1027 files [00:02, 356.09 files/s]\u001b[A\n",
      "Copying files: 1063 files [00:02, 353.34 files/s]\u001b[A\n",
      "Copying files: 1100 files [00:02, 355.36 files/s]\u001b[A\n",
      "Copying files: 1136 files [00:02, 348.75 files/s]\u001b[A\n",
      "Copying files: 1173 files [00:02, 353.11 files/s]\u001b[A\n",
      "Copying files: 1209 files [00:02, 319.56 files/s]\u001b[A\n",
      "Copying files: 1242 files [00:03, 311.92 files/s]\u001b[A\n",
      "Copying files: 1277 files [00:03, 320.03 files/s]\u001b[A\n",
      "Copying files: 1312 files [00:03, 326.88 files/s]\u001b[A\n",
      "Copying files: 1348 files [00:03, 334.54 files/s]\u001b[A\n",
      "Copying files: 1385 files [00:03, 342.79 files/s]\u001b[A\n",
      "Copying files: 1420 files [00:03, 344.18 files/s]\u001b[A\n",
      "Copying files: 1455 files [00:03, 345.16 files/s]\u001b[A\n",
      "Copying files: 1490 files [00:03, 344.83 files/s]\u001b[A\n",
      "Copying files: 1526 files [00:03, 346.49 files/s]\u001b[A\n",
      "Copying files: 1561 files [00:03, 339.73 files/s]\u001b[A\n",
      "Copying files: 1596 files [00:04, 324.92 files/s]\u001b[A\n",
      "Copying files: 1629 files [00:04, 295.21 files/s]\u001b[A\n",
      "Copying files: 1666 files [00:04, 312.10 files/s]\u001b[A\n",
      "Copying files: 1700 files [00:04, 305.58 files/s]\u001b[A\n",
      "Copying files: 1735 files [00:04, 317.04 files/s]\u001b[A\n",
      "Copying files: 1768 files [00:04, 289.03 files/s]\u001b[A\n",
      "Copying files: 1798 files [00:04, 291.46 files/s]\u001b[A\n",
      "Copying files: 1831 files [00:04, 301.44 files/s]\u001b[A\n",
      "Copying files: 1866 files [00:04, 312.24 files/s]\u001b[A\n",
      "Copying files: 1898 files [00:05, 309.31 files/s]\u001b[A\n",
      "Copying files: 1930 files [00:05, 300.39 files/s]\u001b[A\n",
      "Copying files: 1961 files [00:05, 264.66 files/s]\u001b[A\n",
      "Copying files: 1990 files [00:05, 271.23 files/s]\u001b[A\n",
      "Copying files: 2018 files [00:05, 213.56 files/s]\u001b[A\n",
      "Copying files: 2057 files [00:05, 246.28 files/s]\u001b[A\n",
      "Copying files: 2087 files [00:05, 258.39 files/s]\u001b[A\n",
      "Copying files: 2126 files [00:05, 287.03 files/s]\u001b[A\n",
      "Copying files: 2161 files [00:06, 301.27 files/s]\u001b[A\n",
      "Copying files: 2196 files [00:06, 312.11 files/s]\u001b[A\n",
      "Copying files: 2236 files [00:06, 332.33 files/s]\u001b[A\n",
      "Copying files: 2275 files [00:06, 346.57 files/s]\u001b[A\n",
      "Copying files: 2314 files [00:06, 357.82 files/s]\u001b[A\n",
      "Copying files: 2353 files [00:06, 365.13 files/s]\u001b[A\n",
      "Copying files: 2394 files [00:06, 374.70 files/s]\u001b[A\n",
      "Copying files: 2433 files [00:06, 293.90 files/s]\u001b[A\n",
      "Copying files: 2476 files [00:06, 323.47 files/s]\u001b[A\n",
      "Copying files: 2514 files [00:07, 337.02 files/s]\u001b[A\n",
      "Copying files: 2555 files [00:07, 353.53 files/s]\u001b[A\n",
      "Copying files: 2597 files [00:07, 368.48 files/s]\u001b[A\n",
      "Copying files: 2636 files [00:07, 373.90 files/s]\u001b[A\n",
      "Copying files: 2675 files [00:07, 371.33 files/s]\u001b[A\n",
      "Copying files: 2713 files [00:07, 358.35 files/s]\u001b[A\n",
      "Copying files: 2750 files [00:07, 344.88 files/s]\u001b[A\n",
      "Copying files: 2786 files [00:07, 334.96 files/s]\u001b[A\n",
      "Copying files: 2820 files [00:07, 324.23 files/s]\u001b[A\n",
      "Copying files: 2853 files [00:08, 306.27 files/s]\u001b[A\n",
      "Copying files: 2885 files [00:08, 306.94 files/s]\u001b[A\n",
      "Copying files: 2918 files [00:08, 311.98 files/s]\u001b[A\n",
      "Copying files: 2951 files [00:08, 315.60 files/s]\u001b[A\n",
      "Copying files: 2984 files [00:08, 319.11 files/s]\u001b[A\n",
      "Copying files: 3017 files [00:08, 318.82 files/s]\u001b[A\n",
      "Copying files: 3049 files [00:08, 317.53 files/s]\u001b[A\n",
      "Copying files: 3081 files [00:08, 310.21 files/s]\u001b[A\n",
      "Copying files: 3113 files [00:08, 310.60 files/s]\u001b[A\n",
      "Copying files: 3147 files [00:08, 315.57 files/s]\u001b[A\n",
      "Copying files: 3179 files [00:09, 315.26 files/s]\u001b[A\n",
      "Copying files: 3215 files [00:09, 326.82 files/s]\u001b[A\n",
      "Copying files: 3248 files [00:09, 322.28 files/s]\u001b[A\n",
      "Copying files: 3284 files [00:09, 331.15 files/s]\u001b[A\n",
      "Copying files: 3318 files [00:09, 328.23 files/s]\u001b[A\n",
      "Copying files: 3351 files [00:09, 322.29 files/s]\u001b[A\n",
      "Copying files: 3385 files [00:09, 324.85 files/s]\u001b[A\n",
      "Copying files: 3419 files [00:09, 326.67 files/s]\u001b[A\n",
      "Copying files: 3452 files [00:09, 317.50 files/s]\u001b[A\n",
      "Copying files: 3484 files [00:10, 280.15 files/s]\u001b[A\n",
      "Copying files: 3513 files [00:10, 270.60 files/s]\u001b[A\n",
      "Copying files: 3541 files [00:10, 268.08 files/s]\u001b[A\n",
      "Copying files: 3600 files [00:10, 342.76 files/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import split_folders\n",
    "split_folders.ratio('data/newImage/', output=\"./data1\", seed=1337, ratio=(.8, .2)) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 6 classes.\n",
      "Found 480 images belonging to 6 classes.\n",
      "Found 1200 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255, # rescale all pixel values from 0-255, so aftre this step all our pixel values are in range (0,1)\n",
    "shear_range=0.2, #to apply some random tranfromations\n",
    "zoom_range=0.2, #to apply zoom\n",
    "horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('data1/train', target_size=(64, 64), batch_size=32, class_mode='categorical', shuffle = True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('data1/val', target_size=(64, 64), batch_size=32, class_mode='categorical', shuffle = True )\n",
    "\n",
    "test_actual = test_datagen.flow_from_directory('data1/Test Images', target_size=(64, 64), batch_size=32, class_mode='categorical', shuffle = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 93,638\n",
      "Trainable params: 93,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "60 15 <class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 115s 1s/step - loss: 1.7928 - accuracy: 0.1787 - val_loss: 1.7828 - val_accuracy: 0.2305\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 91s 908ms/step - loss: 1.7873 - accuracy: 0.1950 - val_loss: 1.7776 - val_accuracy: 0.2495\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 85s 846ms/step - loss: 1.7815 - accuracy: 0.2106 - val_loss: 1.7823 - val_accuracy: 0.1983\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 81s 808ms/step - loss: 1.7797 - accuracy: 0.2094 - val_loss: 1.7715 - val_accuracy: 0.1956\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 1.7735 - accuracy: 0.2094 - val_loss: 1.7606 - val_accuracy: 0.2297\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 1.7667 - accuracy: 0.2322 - val_loss: 1.7964 - val_accuracy: 0.2348\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 86s 858ms/step - loss: 1.7553 - accuracy: 0.2294 - val_loss: 1.7367 - val_accuracy: 0.2367\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 99s 989ms/step - loss: 1.7522 - accuracy: 0.2259 - val_loss: 1.7810 - val_accuracy: 0.2509\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 84s 838ms/step - loss: 1.7381 - accuracy: 0.2347 - val_loss: 1.6843 - val_accuracy: 0.2861\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 87s 869ms/step - loss: 1.7262 - accuracy: 0.2544 - val_loss: 1.6562 - val_accuracy: 0.2723\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 92s 922ms/step - loss: 1.7223 - accuracy: 0.2484 - val_loss: 1.5842 - val_accuracy: 0.2591\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 88s 877ms/step - loss: 1.7221 - accuracy: 0.2537 - val_loss: 1.7136 - val_accuracy: 0.2334\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 82s 821ms/step - loss: 1.7134 - accuracy: 0.2481 - val_loss: 1.6958 - val_accuracy: 0.2480\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.7121 - accuracy: 0.2531 - val_loss: 1.6392 - val_accuracy: 0.2459\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 83s 830ms/step - loss: 1.7075 - accuracy: 0.2581 - val_loss: 1.5540 - val_accuracy: 0.3206\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 87s 870ms/step - loss: 1.6972 - accuracy: 0.2744 - val_loss: 1.7496 - val_accuracy: 0.2973\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 1.7017 - accuracy: 0.2859 - val_loss: 1.7675 - val_accuracy: 0.2970\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 111s 1s/step - loss: 1.7056 - accuracy: 0.2856 - val_loss: 1.6848 - val_accuracy: 0.2802\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 1.6919 - accuracy: 0.2784 - val_loss: 1.6910 - val_accuracy: 0.3067\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 90s 902ms/step - loss: 1.6791 - accuracy: 0.2856 - val_loss: 1.6947 - val_accuracy: 0.3455\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 91s 905ms/step - loss: 1.6888 - accuracy: 0.2900 - val_loss: 1.6183 - val_accuracy: 0.3141\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 84s 839ms/step - loss: 1.6766 - accuracy: 0.2922 - val_loss: 1.5318 - val_accuracy: 0.3084\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 1.6747 - accuracy: 0.3088 - val_loss: 1.7278 - val_accuracy: 0.3080\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 81s 812ms/step - loss: 1.6692 - accuracy: 0.2966 - val_loss: 1.6331 - val_accuracy: 0.3319\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 83s 828ms/step - loss: 1.6490 - accuracy: 0.3253 - val_loss: 1.7794 - val_accuracy: 0.3470\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 82s 822ms/step - loss: 1.6617 - accuracy: 0.2928 - val_loss: 1.6153 - val_accuracy: 0.3534\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 90s 896ms/step - loss: 1.6532 - accuracy: 0.3028 - val_loss: 1.6764 - val_accuracy: 0.3455\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 1.6526 - accuracy: 0.3091 - val_loss: 1.7001 - val_accuracy: 0.3250\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.6372 - accuracy: 0.3175 - val_loss: 1.5035 - val_accuracy: 0.3347\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 1.6397 - accuracy: 0.3150 - val_loss: 1.4822 - val_accuracy: 0.3591\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 1.6346 - accuracy: 0.3241 - val_loss: 1.5164 - val_accuracy: 0.3478\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 90s 900ms/step - loss: 1.6372 - accuracy: 0.3181 - val_loss: 1.5780 - val_accuracy: 0.3395\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 92s 922ms/step - loss: 1.6230 - accuracy: 0.3269 - val_loss: 1.5087 - val_accuracy: 0.3520\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 1.6309 - accuracy: 0.3303 - val_loss: 1.5857 - val_accuracy: 0.3681\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 93s 935ms/step - loss: 1.6151 - accuracy: 0.3291 - val_loss: 1.4261 - val_accuracy: 0.3495\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 1.6080 - accuracy: 0.3359 - val_loss: 1.5020 - val_accuracy: 0.3634\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 90s 903ms/step - loss: 1.6138 - accuracy: 0.3309 - val_loss: 1.5178 - val_accuracy: 0.3688\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 100s 998ms/step - loss: 1.6175 - accuracy: 0.3334 - val_loss: 1.4983 - val_accuracy: 0.3577\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 1.6063 - accuracy: 0.3381 - val_loss: 1.7045 - val_accuracy: 0.3616\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 108s 1s/step - loss: 1.5982 - accuracy: 0.3272 - val_loss: 1.6165 - val_accuracy: 0.3700\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 107s 1s/step - loss: 1.6076 - accuracy: 0.3422 - val_loss: 1.5940 - val_accuracy: 0.3800\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 1.5958 - accuracy: 0.3388 - val_loss: 1.4835 - val_accuracy: 0.3709\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 90s 897ms/step - loss: 1.6149 - accuracy: 0.3322 - val_loss: 1.5429 - val_accuracy: 0.3852\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 87s 867ms/step - loss: 1.5909 - accuracy: 0.3544 - val_loss: 1.5316 - val_accuracy: 0.3745\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 94s 936ms/step - loss: 1.5896 - accuracy: 0.3300 - val_loss: 1.5546 - val_accuracy: 0.3741\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 101s 1s/step - loss: 1.5857 - accuracy: 0.3491 - val_loss: 1.7156 - val_accuracy: 0.3816\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 1.5972 - accuracy: 0.3397 - val_loss: 1.5967 - val_accuracy: 0.3423\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 100s 1s/step - loss: 1.5941 - accuracy: 0.3334 - val_loss: 1.5278 - val_accuracy: 0.3745\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 1.5891 - accuracy: 0.3525 - val_loss: 1.4694 - val_accuracy: 0.3769\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 1.5889 - accuracy: 0.3547 - val_loss: 1.5886 - val_accuracy: 0.3655\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 1.5950 - accuracy: 0.3537 - val_loss: 1.5273 - val_accuracy: 0.3605\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 90s 899ms/step - loss: 1.5825 - accuracy: 0.3503 - val_loss: 1.6921 - val_accuracy: 0.3600\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 1.5839 - accuracy: 0.3450 - val_loss: 1.4401 - val_accuracy: 0.3617\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 96s 962ms/step - loss: 1.5902 - accuracy: 0.3469 - val_loss: 1.6359 - val_accuracy: 0.3697\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.5953 - accuracy: 0.3422 - val_loss: 1.6185 - val_accuracy: 0.3787\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.5713 - accuracy: 0.3569 - val_loss: 1.5450 - val_accuracy: 0.3755\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.5662 - accuracy: 0.3534 - val_loss: 1.4304 - val_accuracy: 0.3733\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 99s 986ms/step - loss: 1.5704 - accuracy: 0.3553 - val_loss: 1.4914 - val_accuracy: 0.3752\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 100s 1s/step - loss: 1.5758 - accuracy: 0.3475 - val_loss: 1.5681 - val_accuracy: 0.3769\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 1.5676 - accuracy: 0.3575 - val_loss: 1.5115 - val_accuracy: 0.3797\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 1.5710 - accuracy: 0.3450 - val_loss: 1.5558 - val_accuracy: 0.3880\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 96s 963ms/step - loss: 1.5814 - accuracy: 0.3528 - val_loss: 1.4847 - val_accuracy: 0.3891\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 91s 912ms/step - loss: 1.5685 - accuracy: 0.3594 - val_loss: 1.8760 - val_accuracy: 0.3305\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 1.5741 - accuracy: 0.3547 - val_loss: 1.5564 - val_accuracy: 0.3858\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 1.5697 - accuracy: 0.3584 - val_loss: 1.4307 - val_accuracy: 0.3834\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 1.5766 - accuracy: 0.3525 - val_loss: 1.5235 - val_accuracy: 0.3559\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 90s 899ms/step - loss: 1.5692 - accuracy: 0.3634 - val_loss: 1.5525 - val_accuracy: 0.3844\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 90s 902ms/step - loss: 1.5675 - accuracy: 0.3516 - val_loss: 1.5142 - val_accuracy: 0.3875\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 1.5676 - accuracy: 0.3634 - val_loss: 1.6200 - val_accuracy: 0.3594\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 1.5638 - accuracy: 0.3628 - val_loss: 1.5314 - val_accuracy: 0.3816\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 1.5799 - accuracy: 0.3472 - val_loss: 1.5565 - val_accuracy: 0.3684\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 1.5544 - accuracy: 0.3634 - val_loss: 1.2684 - val_accuracy: 0.3841\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 91s 907ms/step - loss: 1.5756 - accuracy: 0.3522 - val_loss: 1.3226 - val_accuracy: 0.3872\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 87s 867ms/step - loss: 1.5581 - accuracy: 0.3669 - val_loss: 1.3546 - val_accuracy: 0.3747\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 93s 933ms/step - loss: 1.5632 - accuracy: 0.3725 - val_loss: 1.3924 - val_accuracy: 0.3706\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 99s 990ms/step - loss: 1.5628 - accuracy: 0.3547 - val_loss: 1.5855 - val_accuracy: 0.3906\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 99s 990ms/step - loss: 1.5774 - accuracy: 0.3616 - val_loss: 1.4781 - val_accuracy: 0.3837\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 100s 1s/step - loss: 1.5618 - accuracy: 0.3622 - val_loss: 1.4585 - val_accuracy: 0.3761\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 93s 935ms/step - loss: 1.5596 - accuracy: 0.3519 - val_loss: 1.6613 - val_accuracy: 0.3836\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 1.5621 - accuracy: 0.3653 - val_loss: 1.4656 - val_accuracy: 0.3753\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 1.5581 - accuracy: 0.3603 - val_loss: 1.8329 - val_accuracy: 0.3783\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 1.5664 - accuracy: 0.3678 - val_loss: 1.5006 - val_accuracy: 0.3755\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 90s 901ms/step - loss: 1.5606 - accuracy: 0.3487 - val_loss: 1.5590 - val_accuracy: 0.3814\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 87s 867ms/step - loss: 1.5612 - accuracy: 0.3562 - val_loss: 1.5300 - val_accuracy: 0.3530\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 91s 905ms/step - loss: 1.5559 - accuracy: 0.3716 - val_loss: 1.4437 - val_accuracy: 0.3812\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 89s 888ms/step - loss: 1.5692 - accuracy: 0.3709 - val_loss: 1.5512 - val_accuracy: 0.3877\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 1.5607 - accuracy: 0.3600 - val_loss: 1.5065 - val_accuracy: 0.3877\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 1.5500 - accuracy: 0.3666 - val_loss: 1.5971 - val_accuracy: 0.3798\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 94s 938ms/step - loss: 1.5629 - accuracy: 0.3663 - val_loss: 1.6110 - val_accuracy: 0.3762\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 1.5591 - accuracy: 0.3575 - val_loss: 1.5261 - val_accuracy: 0.3769\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 1.5449 - accuracy: 0.3791 - val_loss: 1.4290 - val_accuracy: 0.3800\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 92s 920ms/step - loss: 1.5437 - accuracy: 0.3797 - val_loss: 1.4798 - val_accuracy: 0.3769\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 87s 867ms/step - loss: 1.5602 - accuracy: 0.3628 - val_loss: 1.4706 - val_accuracy: 0.3702\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 91s 907ms/step - loss: 1.5507 - accuracy: 0.3666 - val_loss: 1.2910 - val_accuracy: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "100/100 [==============================] - 92s 918ms/step - loss: 1.5579 - accuracy: 0.3653 - val_loss: 1.5691 - val_accuracy: 0.3775\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 1.5456 - accuracy: 0.3697 - val_loss: 1.6622 - val_accuracy: 0.3953\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 93s 933ms/step - loss: 1.5510 - accuracy: 0.3691 - val_loss: 1.5932 - val_accuracy: 0.3878\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 1.5515 - accuracy: 0.3725 - val_loss: 1.4966 - val_accuracy: 0.3819\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 1.5467 - accuracy: 0.3616 - val_loss: 1.5193 - val_accuracy: 0.3716\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 1.5505 - accuracy: 0.3706 - val_loss: 1.5598 - val_accuracy: 0.3584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x244b9932948>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resFile = 'CNN'\n",
    "model = Sequential()\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "# 1st hidden layer\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 3rd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "print(len(training_set), len(test_set), type(training_set))\n",
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(training_set, steps_per_epoch=100, epochs=100, validation_data=test_set, validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 245ms/step\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_generator(test_actual, steps=100, verbose=1)\n",
    "predicted_class_indices=np.argmax(predicted,axis=1)\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "#predictions = predictions[:1200]\n",
    "df = pd.read_csv('data/test_idx.csv')\n",
    "\n",
    "i = 0\n",
    "final = []\n",
    "for index, row in df.iterrows():\n",
    "    row1 = [row[0], predictions[i]]\n",
    "    final.append(row1)\n",
    "    i += 1\n",
    "\n",
    "df2 = pd.DataFrame(data = final, columns = ['id', 'genre'])\n",
    "df2.to_csv('data/fin_CNN.csv', index = False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [model]\n",
    "np.save('data/CNN_newImage',li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = np.load('CNN_newImage.npy', allow_pickle = True)\n",
    "model = li[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4593749940395355\n"
     ]
    }
   ],
   "source": [
    "metric = model.evaluate_generator(generator=test_set,\n",
    "steps=100)\n",
    "print('Accuracy: ', metric[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
